import streamlit as st
import pandas as pd
from io import StringIO

# --------------------------------------------------------------------------
# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯éƒ¨
# --------------------------------------------------------------------------
def generate_prompt(
    problem_type, ts_task_type,
    source_type, analysis_goal, data_context,
    train_path, test_path, submit_path, single_path,
    target_col, id_col, time_col,
    models, use_ensemble, tune_hyperparams,
    ts_features, include_corr, include_scaling, graphs,
    save_dir_path,
    use_feature_selection, n_top_features
    ):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é¸æŠã«åŸºã¥ã„ã¦AIã¸ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°"""

    # å•é¡Œã‚¿ã‚¤ãƒ—ã®æ–‡å­—åˆ—ã‚’æ•´å½¢
    if problem_type == "æ™‚ç³»åˆ—":
        problem_type_full = f"æ™‚ç³»åˆ—{ts_task_type}"
    else:
        problem_type_full = problem_type

    prompt = [
        f"### ä¾é ¼å†…å®¹ï¼šæ©Ÿæ¢°å­¦ç¿’ã‚’ç”¨ã„ãŸã€Œ{problem_type_full}ã€ã®ã€Œ{analysis_goal}ã€",
        "ã“ã‚Œã‹ã‚‰Google Colabç’°å¢ƒã§å®Ÿè¡Œã™ã‚‹ã€ãƒ‡ãƒ¼ã‚¿åˆ†æã®Pythonã‚³ãƒ¼ãƒ‰ã‚’ã‚¹ãƒ†ãƒƒãƒ—ãƒ»ãƒã‚¤ãƒ»ã‚¹ãƒ†ãƒƒãƒ—ã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚",
        "### æŒ‡ç¤ºã®å‰ææ¡ä»¶:",
        "- **å†ç¾æ€§ã®ç¢ºä¿**: åˆ†æã®å†ç¾æ€§ãŒå–ã‚Œã‚‹ã‚ˆã†ã€ãƒ¢ãƒ‡ãƒ«ã® `random_state` ã¯ `42` ã«å›ºå®šã—ã¦ãã ã•ã„ã€‚",
        "- **å¯èª­æ€§ã®å‘ä¸Š**: é©åˆ‡ãªã‚³ãƒ¡ãƒ³ãƒˆã‚’è¿½åŠ ã—ã€å¯èƒ½ã§ã‚ã‚Œã°å‡¦ç†ã‚’é–¢æ•°ã«ã¾ã¨ã‚ã¦ã‚³ãƒ¼ãƒ‰ã®å¯èª­æ€§ã‚’é«˜ã‚ã¦ãã ã•ã„ã€‚",
        "\n# ==================================",
        "# Step 1: ç’°å¢ƒè¨­å®šã¨ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿",
        "# ==================================",
        "### ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«",
        "!pip install japanize-matplotlib lightgbm shap holidays scikit-learn tsfresh -q",
        "\n### ä¸»è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ",
        "# (pandas, numpy, lightgbm, sklearn, matplotlib, seaborn, shap, holidays, os ãªã©ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¦ãã ã•ã„)",
        "\n### Google Driveã®ãƒã‚¦ãƒ³ãƒˆ",
        "from google.colab import drive", "drive.mount('/content/drive')",
        "\n### ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã¨ä¿å­˜å…ˆã®è¨­å®š",
    ]

    if source_type == "Kaggleå½¢å¼":
        prompt.append(f"train_data_path = '{train_path}'")
        prompt.append(f"test_data_path = '{test_path}'")
        prompt.append(f"submit_template_path = '{submit_path}'")
    else:
        prompt.append(f"file_path = '{single_path}'")
    prompt.append(f"save_folder_path = '{save_dir_path}'")

    prompt.append("\n### ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿")
    if source_type == "Kaggleå½¢å¼":
        prompt.append("df_train = pd.read_csv(train_data_path)")
        prompt.append("df_test = pd.read_csv(test_data_path)")
    else:
        prompt.append("df = pd.read_csv(file_path)")

    prompt.extend([
        "\n# ==================================", "# Step 2: ãƒ‡ãƒ¼ã‚¿æ¦‚è¦ã®æŠŠæ¡", "# ==================================",
        "### ãƒ‡ãƒ¼ã‚¿ã®ã‚«ãƒ©ãƒ åã¨ã‚µãƒ³ãƒ—ãƒ«",
        "ä»¥ä¸‹ã«ã€åˆ†æå¯¾è±¡ã¨ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã®ã‚«ãƒ©ãƒ æ§‹æˆã¨å…ˆé ­æ•°è¡Œã®ã‚µãƒ³ãƒ—ãƒ«ã‚’ç¤ºã—ã¾ã™ã€‚ã“ã‚Œã‚’å…ƒã«åˆ†æã‚’é€²ã‚ã¦ãã ã•ã„ã€‚",
        "--- ãƒ‡ãƒ¼ã‚¿æ¦‚è¦ ---", data_context, "--- ã“ã“ã¾ã§ ---",
        f"\nä»Šå›ã®åˆ†æã®ç›®çš„å¤‰æ•°ã¯ `{target_col}` ã§ã™ã€‚"
    ])

    prompt.extend([
        "\n# ==================================",
        f"# Step 3: {analysis_goal}ã®ãŸã‚ã®ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã¨å‰å‡¦ç†",
        "# ==================================",
        "### å®Ÿè¡Œã—ã¦ã»ã—ã„ã‚¿ã‚¹ã‚¯:",
    ])

    tasks = [f"- **ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ**: `os.makedirs(save_folder_path, exist_ok=True)` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"]
    
    if problem_type == "æ™‚ç³»åˆ—" and ts_task_type == "åˆ†é¡":
        tasks.append(f"- **ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®å‰æ**: ã“ã®ã‚¿ã‚¹ã‚¯ã¯æ™‚ç³»åˆ—åˆ†é¡ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã¯å„ã‚µãƒ³ãƒ—ãƒ«ï¼ˆIDï¼‰ã”ã¨ã«æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’æŒã¤ãƒ­ãƒ³ã‚°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆåˆ—: `{id_col}`, `{time_col}`, å€¤, `{target_col}`ï¼‰ã§ã‚ã‚‹ã“ã¨ã‚’å‰æã¨ã—ã¦ãã ã•ã„ã€‚")
        tasks.append(f"- **ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°**: å„ã‚µãƒ³ãƒ—ãƒ«IDã®æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€**ç³»åˆ—å…¨ä½“ã‚’è¦ç´„ã™ã‚‹ç‰¹å¾´é‡**ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚å…·ä½“çš„ã«ã¯ã€å¹³å‡å€¤ã€æ¨™æº–åå·®ã€æœ€å¤§å€¤ã€æœ€å°å€¤ã€æ­ªåº¦ã€å°–åº¦ãªã©ã§ã™ã€‚å¯èƒ½ã§ã‚ã‚Œã°`tsfresh`ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®æ´»ç”¨ã‚‚æ¤œè¨ã—ã¦ãã ã•ã„ã€‚")
    elif problem_type == "æ™‚ç³»åˆ—" and ts_task_type == "äºˆæ¸¬":
        if source_type == "Kaggleå½¢å¼": tasks.append("- **ãƒ‡ãƒ¼ã‚¿çµåˆ**: `df_train`ã¨`df_test`ã‚’ä¸€åº¦çµåˆã—ã€å…±é€šã®å‰å‡¦ç†ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚")
        tasks.append(f"- **æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†**: `{time_col}`åˆ—ã‚’datetimeå‹ã«å¤‰æ›ã—ã¦ãã ã•ã„ã€‚")
        if ts_features: tasks.append(f"- **æ™‚ç³»åˆ—ç‰¹å¾´é‡ã®ä½œæˆ**: ä»¥ä¸‹ã®ç‰¹å¾´é‡ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n  - " + "\n  - ".join(ts_features))
    else:
        if source_type == "Kaggleå½¢å¼": tasks.append("- **ãƒ‡ãƒ¼ã‚¿çµåˆ**: `df_train`ã¨`df_test`ã‚’ä¸€åº¦çµåˆã—ã€å…±é€šã®å‰å‡¦ç†ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚")
        tasks.append("- **ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®å‡¦ç†**: **å„ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯æ•°ã‚’èª¿æŸ»**ã—ã€ãã®æ•°ã«å¿œã˜ã¦ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’é©åˆ‡ã«ä½¿ã„åˆ†ã‘ã¦ãã ã•ã„ã€‚ç‰¹ã«LightGBMã‚’ä½¿ã†å ´åˆã¯ã€ãƒ¯ãƒ³ãƒ›ãƒƒãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã¯ãªãã€`category`å‹ã¸ã®å¤‰æ›ã¨ãƒ¢ãƒ‡ãƒ«ã¸ã®ç›´æ¥æŒ‡å®šãŒæœ‰åŠ¹ã§ã™ã€‚")

    tasks.append("- **æ¬ æå€¤å‡¦ç†**: æ¬ æå€¤ã®æœ‰ç„¡ã‚’ç¢ºèªã—ã€ã‚‚ã—å­˜åœ¨ã™ã‚Œã°é©åˆ‡ãªæ–¹æ³•ã§å‡¦ç†ã—ã¦ãã ã•ã„ã€‚")
    if include_scaling:
        tasks.append("- **ç‰¹å¾´é‡ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°**: `StandardScaler`ãªã©ã‚’ç”¨ã„ã¦ã€æ•°å€¤ç‰¹å¾´é‡ã®ã‚¹ã‚±ãƒ¼ãƒ«ã‚’æƒãˆã‚‹å‡¦ç†ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚")
    if include_corr:
        tasks.append("- **ç›¸é–¢åˆ†æ**: å‰å‡¦ç†å¾Œã®ç‰¹å¾´é‡é–“ã®ç›¸é–¢è¡Œåˆ—ã‚’è¨ˆç®—ã—ã€ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã§å¯è¦–åŒ–ã—ã¦ãã ã•ã„ã€‚")

    prompt.append("\n".join(tasks))

    prompt.extend([
        "\n# ==================================",
        f"# Step 4: {analysis_goal}ã®ãŸã‚ã®ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ã¨è©•ä¾¡ (åˆå›)",
        "# ==================================",
        "### å®Ÿè¡Œã—ã¦ã»ã—ã„ã‚¿ã‚¹ã‚¯:",
    ])
    
    tasks = []
    tasks.append(f"- **ãƒ¢ãƒ‡ãƒ«å­¦ç¿’**: `{', '.join(models)}` ã‚’ä½¿ã£ã¦ã€äºˆæ¸¬ç²¾åº¦ãŒæœ€å¤§ã«ãªã‚‹ã‚ˆã†ã«ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã•ã›ã¦ãã ã•ã„ã€‚")
    if 'ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°/ç·šå½¢å›å¸°' in models:
        tasks.append("- **äºˆæ¸¬å¼ã®è¡¨ç¤º**: ç·šå½¢å›å¸°ã¾ãŸã¯ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ã•ã‚ŒãŸå ´åˆã€ãã®ãƒ¢ãƒ‡ãƒ«ã®ä¿‚æ•°ï¼ˆ`coef_`ï¼‰ã¨åˆ‡ç‰‡ï¼ˆ`intercept_`ï¼‰ã‚’è¡¨ç¤ºã—ã€äºˆæ¸¬å¼ã‚’äººé–“ãŒç†è§£ã§ãã‚‹å½¢ã§ç¤ºã—ã¦ãã ã•ã„ã€‚")

    if tune_hyperparams and models and not any(m in ["ARIMA", "Prophet"] for m in models):
        cv_method = "TimeSeriesSplitã‚’ä½¿ã£ãŸã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³" if problem_type == "æ™‚ç³»åˆ—" and ts_task_type == "äºˆæ¸¬" else "é€šå¸¸ã®ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³(cv=5)"
        tasks.append(f"- **ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°**: GridSearchCVã‚’ä½¿ã„ã€`{models[0]}`ã®ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ç²¾åº¦ã‚’ã•ã‚‰ã«å‘ä¸Šã•ã›ã¦ãã ã•ã„ã€‚({cv_method})")
    if use_ensemble and len(models) > 1:
        tasks.append("- **ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«**: å­¦ç¿’ã•ã›ãŸè¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬å€¤ã‚’å¹³å‡ã—ã€ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚")

    evaluation_items = []
    if problem_type == "åˆ†é¡" or (problem_type == "æ™‚ç³»åˆ—" and ts_task_type == "åˆ†é¡"):
        evaluation_items = ["æ··åŒè¡Œåˆ—", "æ­£è§£ç‡ (Accuracy), é©åˆç‡ (Precision), å†ç¾ç‡ (Recall), F1ã‚¹ã‚³ã‚¢", "AUCã‚¹ã‚³ã‚¢"]
    elif problem_type == "å›å¸°" or (problem_type == "æ™‚ç³»åˆ—" and ts_task_type == "äºˆæ¸¬"):
        evaluation_items = ["RMSE", "MAE", "R2ã‚¹ã‚³ã‚¢ (æ±ºå®šä¿‚æ•°)"]
        if problem_type == "æ™‚ç³»åˆ—": evaluation_items.append("MAPE")
        
    if evaluation_items:
        tasks.append(f"\n- **ãƒ¢ãƒ‡ãƒ«è©•ä¾¡**: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆã¾ãŸã¯æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ï¼‰ã«å¯¾ã—ã¦ã€ä»¥ä¸‹ã®æŒ‡æ¨™ã‚’è¨ˆç®—ã—ã€çµæœã‚’å ±å‘Šã—ã¦ãã ã•ã„ã€‚\n  - " + "\n  - ".join(evaluation_items))
        tasks.append("- **è©•ä¾¡æŒ‡æ¨™ã®ç°¡å˜ãªè§£èª¬**: è¨ˆç®—ã•ã‚ŒãŸå„è©•ä¾¡æŒ‡æ¨™ã«ã¤ã„ã¦ã€ãã®å€¤ãŒä¸€èˆ¬çš„ã«ã€Œé«˜ã„ã€ã®ã‹ã€Œä½ã„ã€ã®ã‹ã€ãã‚ŒãŒä½•ã‚’æ„å‘³ã™ã‚‹ã®ã‹ã‚’åˆå¿ƒè€…ã«ã‚‚åˆ†ã‹ã‚‹ã‚ˆã†ã«ç°¡å˜ã«è§£èª¬ã—ã¦ãã ã•ã„ã€‚")

    tasks.append(f"\n- **å¯è¦–åŒ–**: ä»¥ä¸‹ã®ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆã—ã€`save_folder_path`ã«ä¿å­˜ã—ã¦ãã ã•ã„ã€‚\n  - " + "\n  - ".join(graphs))
    if any("SHAP" in g for g in graphs):
        tasks.append("- **é‡è¦åº¦ã®é«˜ã„ãƒ»ä½ã„ç‰¹å¾´é‡ã®ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—**: SHAPã®åˆ†æçµæœã«åŸºã¥ãã€æœ€ã‚‚é‡è¦åº¦ãŒé«˜ã‹ã£ãŸç‰¹å¾´é‡ãƒˆãƒƒãƒ—5ã¨ã€æœ€ã‚‚é‡è¦åº¦ãŒä½ã‹ã£ãŸç‰¹å¾´é‡ãƒ¯ãƒ¼ã‚¹ãƒˆ5ã‚’ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—ã—ã¦ãã ã•ã„ã€‚")
    
    prompt.append("\n".join(tasks))

    def create_submission_tasks(is_kaggle, problem, id_col_name):
        submission_tasks = []
        if is_kaggle:
            submission_tasks.append("- **äºˆæ¸¬çµæœã®è¡¨ç¤ºã¨è¦ç´„**: æœ€çµ‚çš„ãªäºˆæ¸¬çµæœã®å…ˆé ­5è¡Œã¨ã€ãã®åŸºæœ¬çµ±è¨ˆé‡ï¼ˆå¹³å‡ã€æ¨™æº–åå·®ãªã©ï¼‰ã‚’è¡¨ç¤ºã—ã¦ãã ã•ã„ã€‚")
            submission_tasks.append(f"- **æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ**: `sample_submission.csv`ã®å½¢å¼ã«åˆã‚ã›ã¦ã€ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®äºˆæ¸¬çµæœã‚’`os.path.join(save_folder_path, 'submission.csv')`ã¨ã—ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚IDåˆ—ã¯`{id_col_name}`ã§ã™ã€‚")
        elif problem == "æ™‚ç³»åˆ—äºˆæ¸¬":
            submission_tasks.append("\n- **æœªæ¥äºˆæ¸¬**: å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã„ã€æœªæ¥ã®äºˆæ¸¬å€¤ã‚’ç®—å‡ºã—ã€å®Ÿç¸¾å€¤ã¨åˆã‚ã›ã¦ã‚°ãƒ©ãƒ•ã«ãƒ—ãƒ­ãƒƒãƒˆã—ã¦ãã ã•ã„ã€‚")
        return submission_tasks

    if use_feature_selection and 'LightGBM' in models:
        prompt.extend([
            "\n# ==================================",
            "# Step 5: ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ã®ç‰¹å¾´é‡é¸æŠã¨å†æ§‹ç¯‰",
            "# ==================================", "### å®Ÿè¡Œã—ã¦ã»ã—ã„ã‚¿ã‚¹ã‚¯:",
            f"- **ç‰¹å¾´é‡é¸æŠ**: Step 4ã§å­¦ç¿’ã—ãŸLightGBMãƒ¢ãƒ‡ãƒ«ã® `feature_importances_` ã‚’åˆ©ç”¨ã—ã¦ã€é‡è¦åº¦ã®é«˜ã„ä¸Šä½ **{n_top_features}å€‹** ã®ç‰¹å¾´é‡ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚",
            "- **ãƒ¢ãƒ‡ãƒ«å†æ§‹ç¯‰**: é¸æŠã—ãŸç‰¹å¾´é‡ã®ã¿ã‚’ä½¿ç”¨ã—ã¦ã€å†åº¦LightGBMãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã•ã›ã¦ãã ã•ã„ã€‚ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯Step 4ã§ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸæœ€é©å€¤ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚",
            "- **å†è©•ä¾¡**: æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã‚’åŒã˜æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡ã—ã€Step 4ã®è©•ä¾¡æŒ‡æ¨™ã¨æ¯”è¼ƒã—ã¦ã‚¹ã‚³ã‚¢ãŒæ”¹å–„ã—ãŸã‹å ±å‘Šã—ã¦ãã ã•ã„ã€‚",
        ])
        prompt.extend(create_submission_tasks(source_type == "Kaggleå½¢å¼", problem_type_full, id_col))
    else:
        submission_tasks = create_submission_tasks(source_type == "Kaggleå½¢å¼", problem_type_full, id_col)
        if submission_tasks:
            prompt.append("\n# ==================================")
            prompt.append("# Step 5: æœ€çµ‚äºˆæ¸¬ã¨ãƒ•ã‚¡ã‚¤ãƒ«ã®æå‡º")
            prompt.append("# ==================================")
            prompt.extend(submission_tasks)
    
    prompt.append("\n---\nä»¥ä¸Šã®å†…å®¹ã§ã€Pythonã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚")
    return "\n".join(prompt)

# --------------------------------------------------------------------------
# Streamlit UIéƒ¨
# --------------------------------------------------------------------------
st.set_page_config(page_title="ğŸ¤– AIãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ“ãƒ«ãƒ€ãƒ¼", layout="wide")
st.title("ğŸ¤– AIãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ“ãƒ«ãƒ€ãƒ¼ for Data Analysis")
st.write("ãƒ‡ãƒ¼ã‚¿åˆ†æã®ã‚¿ã‚¹ã‚¯ã‚’AIã«ä¾é ¼ã™ã‚‹ãŸã‚ã®ã€å®Œç’§ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è‡ªå‹•ç”Ÿæˆã—ã¾ã™ã€‚")

if 'data_context' not in st.session_state:
    st.session_state.data_context = ""

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
with st.sidebar:
    st.header("âš™ï¸ è¨­å®šé …ç›®")

    with st.expander("1. åˆ†æã®ç›®çš„", expanded=True):
        analysis_goal = st.radio("ä¸»ãªç›®çš„ã¯ï¼Ÿ", ["äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰", "è¦å› åˆ†æ"], horizontal=True, key="analysis_goal")
        problem_type = st.radio("å•é¡Œã®ç¨®é¡ã¯ï¼Ÿ", ["å›å¸°", "åˆ†é¡", "æ™‚ç³»åˆ—"], horizontal=True, key="problem_type")
        
        ts_task_type = ""
        if problem_type == "æ™‚ç³»åˆ—":
            ts_task_type = st.radio("æ™‚ç³»åˆ—ã‚¿ã‚¹ã‚¯ã‚’é¸æŠ", ["äºˆæ¸¬", "åˆ†é¡"], horizontal=True, key="ts_task_type")

    with st.expander("2. ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹", expanded=True):
        source_type = st.radio("ãƒ‡ãƒ¼ã‚¿ã®å½¢å¼ã¯ï¼Ÿ", ["å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«", "Kaggleå½¢å¼"], horizontal=True, key="source_type")
        st.caption("Google Driveå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        if source_type == "Kaggleå½¢å¼":
            train_path = st.text_input("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ (train.csv)", "/content/drive/MyDrive/data/train.csv")
            test_path = st.text_input("ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ (test.csv)", "/content/drive/MyDrive/data/test.csv")
            submit_path = st.text_input("æå‡ºç”¨ã‚µãƒ³ãƒ—ãƒ«", "/content/drive/MyDrive/data/sample_submission.csv")
            single_path = ""
        else:
            single_path = st.text_input("CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹", "/content/drive/MyDrive/data/my_data.csv")
            train_path, test_path, submit_path = "", "", ""

    with st.expander("3. ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°", expanded=True):
        target_col_default = "y" if problem_type == "æ™‚ç³»åˆ—" and ts_task_type == "äºˆæ¸¬" else "target"
        target_col = st.text_input("ç›®çš„å¤‰æ•°ã®åˆ—å", target_col_default, key="target_col")
        id_col = st.text_input("ID/è­˜åˆ¥å­ã®åˆ—å", "id", key="id_col")
        
        time_col, ts_features = "", []
        if problem_type == "æ™‚ç³»åˆ—":
            time_col_default = "datetime" if ts_task_type == "äºˆæ¸¬" else "timestamp"
            time_col = st.text_input("æ™‚ç³»åˆ—ã‚«ãƒ©ãƒ ã®åˆ—å", time_col_default, key="time_col")
            if ts_task_type == "äºˆæ¸¬":
                ts_features = st.multiselect(
                    "ä½œæˆã—ãŸã„æ™‚ç³»åˆ—ç‰¹å¾´é‡",
                    ["æ™‚é–“ãƒ™ãƒ¼ã‚¹ã®ç‰¹å¾´é‡", "ãƒ©ã‚°ç‰¹å¾´é‡", "ç§»å‹•å¹³å‡ç‰¹å¾´é‡", "ç¥æ—¥ç‰¹å¾´é‡"],
                    default=["æ™‚é–“ãƒ™ãƒ¼ã‚¹ã®ç‰¹å¾´é‡", "ãƒ©ã‚°ç‰¹å¾´é‡", "ç§»å‹•å¹³å‡ç‰¹å¾´é‡"],
                    key="ts_features"
                )

    with st.expander("4. ãƒ‡ãƒ¼ã‚¿æ¦‚è¦", expanded=False):
        st.info("åˆ†æå¯¾è±¡ã®CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ã€æ¦‚è¦ãŒè‡ªå‹•å…¥åŠ›ã•ã‚Œã¾ã™ã€‚")
        uploaded_file = st.file_uploader("CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦æ¦‚è¦ã‚’è‡ªå‹•ç”Ÿæˆ", type=['csv'], key="uploader")
        if uploaded_file:
            try:
                df_context = pd.read_csv(uploaded_file)
                buffer = StringIO()
                df_context.info(buf=buffer)
                info_str = buffer.getvalue()
                head_str = df_context.head().to_markdown()
                st.session_state.data_context = f"ã€df.info()ã€‘\n```\n{info_str}```\n\nã€df.head()ã€‘\n{head_str}"
            except Exception as e: st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        data_context = st.text_area("ãƒ‡ãƒ¼ã‚¿æ¦‚è¦ï¼ˆè‡ªå‹•å…¥åŠ›ï¼‰", st.session_state.data_context, height=300, key="data_context")

    with st.expander("5. ãƒ¢ãƒ‡ãƒ«ã¨åˆ†ææ‰‹æ³•", expanded=True):
        default_models = ["LightGBM"] if problem_type == "æ™‚ç³»åˆ—" else ["LightGBM", "ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°/ç·šå½¢å›å¸°"]
        models = st.multiselect("ä½¿ç”¨ã—ãŸã„ãƒ¢ãƒ‡ãƒ«", ["LightGBM", "ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°/ç·šå½¢å›å¸°", "ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ", "XGBoost", "ARIMA", "Prophet"], default=default_models, key="models")

        tune_hyperparams, use_ensemble, use_feature_selection = False, False, False
        n_top_features = 50
        if analysis_goal == "äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰":
            tune_hyperparams = st.checkbox("ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã†", True, key="tuning")
            if len(models) > 1 and not (problem_type == "æ™‚ç³»åˆ—" and ts_task_type == "åˆ†é¡"):
                use_ensemble = st.checkbox("ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ã‚’è¡Œã†", True, key="ensemble")
            if 'LightGBM' in models:
                use_feature_selection = st.checkbox("ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ã®ç‰¹å¾´é‡é¸æŠã‚’è¡Œã†", True, key="feature_selection")
                if use_feature_selection:
                    n_top_features = st.number_input("é¸æŠã™ã‚‹ä¸Šä½ç‰¹å¾´é‡ã®æ•°", 10, 200, 50, 10, key="n_top_features")

        include_scaling = st.checkbox("ç‰¹å¾´é‡ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’è¡Œã†", True, key="scaling")
        include_corr = st.checkbox("ç›¸é–¢ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’ä½œæˆ", True, key="corr")

    with st.expander("6. å¯è¦–åŒ–ã¨ä¿å­˜å…ˆ", expanded=True):
        graph_options = []
        if problem_type == "åˆ†é¡" or (problem_type == "æ™‚ç³»åˆ—" and ts_task_type == "åˆ†é¡"):
            graph_options = ["ç›®çš„å¤‰æ•°ã®åˆ†å¸ƒ", "æ··åŒè¡Œåˆ—"]
        elif problem_type == "å›å¸°":
            graph_options = ["ç›®çš„å¤‰æ•°ã®åˆ†å¸ƒ", "å®Ÿç¸¾å€¤ vs äºˆæ¸¬å€¤ãƒ—ãƒ­ãƒƒãƒˆ"]
        elif problem_type == "æ™‚ç³»åˆ—" and ts_task_type == "äºˆæ¸¬":
            graph_options = ["æ™‚ç³»åˆ—ã‚°ãƒ©ãƒ•ã®ãƒ—ãƒ­ãƒƒãƒˆ", "æ™‚ç³»åˆ—åˆ†è§£å›³", "ACF/PACFãƒ—ãƒ­ãƒƒãƒˆ"]
        
        if not any(m in ["ARIMA", "Prophet"] for m in models):
             graph_options.extend(["SHAP é‡è¦åº¦ãƒ—ãƒ­ãƒƒãƒˆ (Bar)", "SHAP Beeswarmãƒ—ãƒ­ãƒƒãƒˆ"])
        
        graphs = st.multiselect("ä½œæˆã—ãŸã„ã‚°ãƒ©ãƒ•ã®ç¨®é¡", graph_options, default=graph_options, key="graphs")
        save_dir_path = st.text_input("ä¿å­˜å…ˆãƒ•ã‚©ãƒ«ãƒ€", "/content/drive/MyDrive/results/", key="save_path")

# --- ãƒ¡ã‚¤ãƒ³ç”»é¢ ---
st.header("âœ… ç”Ÿæˆã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ")
st.info("ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ã€AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã«è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„ã€‚")

if all([target_col, data_context, models]):
    generated_prompt_text = generate_prompt(
        problem_type, ts_task_type,
        source_type, analysis_goal, data_context,
        train_path, test_path, submit_path, single_path,
        target_col, id_col, time_col,
        models, use_ensemble, tune_hyperparams,
        ts_features, include_corr, include_scaling, graphs,
        save_dir_path,
        use_feature_selection, n_top_features
    )
    st.text_area("", generated_prompt_text, height=600, label_visibility="collapsed")
else:
    st.warning("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§å¿…é ˆé …ç›®ï¼ˆç‰¹ã«ã€Œç›®çš„å¤‰æ•°ã€ã€ã€Œãƒ‡ãƒ¼ã‚¿æ¦‚è¦ã€ã€ã€Œä½¿ç”¨ã—ãŸã„ãƒ¢ãƒ‡ãƒ«ã€ï¼‰ã‚’å…¥åŠ›ãƒ»é¸æŠã—ã¦ãã ã•ã„ã€‚")

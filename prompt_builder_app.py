import streamlit as st
import pandas as pd
from io import StringIO

# (generate_prompté–¢æ•°ã¯å‰å›ã®å›ç­”ã¨åŒã˜ãªã®ã§ã€ã“ã“ã§ã¯çœç•¥ã—ã¾ã™)
# ...
def generate_prompt(
    problem_type, source_type, analysis_goal, data_context,
    train_path, test_path, submit_path, single_path,
    target_col, id_col, time_col,
    models, use_ensemble, tune_hyperparams,
    ts_features, include_corr, graphs,
    save_dir_path
    ):
    """(å‰å›ã®å›ç­”ã¨åŒã˜ã‚³ãƒ¼ãƒ‰ãŒã“ã“ã«å…¥ã‚Šã¾ã™)"""
    # ...
    # ã“ã®é–¢æ•°ã¯å¤‰æ›´ãªã—
    prompt = [
        f"### ä¾é ¼å†…å®¹ï¼šæ©Ÿæ¢°å­¦ç¿’ã‚’ç”¨ã„ãŸã€Œ{problem_type}ã€ã®ã€Œ{analysis_goal}ã€",
        "ã“ã‚Œã‹ã‚‰Google Colabç’°å¢ƒã§å®Ÿè¡Œã™ã‚‹ã€ãƒ‡ãƒ¼ã‚¿åˆ†æã®Pythonã‚³ãƒ¼ãƒ‰ã‚’ã‚¹ãƒ†ãƒƒãƒ—ãƒ»ãƒã‚¤ãƒ»ã‚¹ãƒ†ãƒƒãƒ—ã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚",
        "\n# ==================================",
        "# Step 1: ç’°å¢ƒè¨­å®šã¨ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿",
        "# ==================================",
        "### ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«",
        "!pip install japanize-matplotlib lightgbm shap holidays -q",
        "\n### ä¸»è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ",
        "# (pandas, numpy, lightgbm, sklearn, matplotlib, seaborn, shap, holidays, os ãªã©ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¦ãã ã•ã„)",
        "\n### Google Driveã®ãƒã‚¦ãƒ³ãƒˆ",
        "from google.colab import drive",
        "drive.mount('/content/drive')",
        "\n### ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã¨ä¿å­˜å…ˆã®è¨­å®š",
    ]

    if source_type == "Kaggleå½¢å¼":
        prompt.append(f"train_data_path = '{train_path}'")
        prompt.append(f"test_data_path = '{test_path}'")
        prompt.append(f"submit_template_path = '{submit_path}'")
    else:
        prompt.append(f"file_path = '{single_path}'")
    prompt.append(f"save_folder_path = '{save_dir_path}'")

    prompt.append("\n### ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿")
    if source_type == "Kaggleå½¢å¼":
        prompt.append("df_train = pd.read_csv(train_data_path)")
        prompt.append("df_test = pd.read_csv(test_data_path)")
    else:
        prompt.append("df = pd.read_csv(file_path)")

    prompt.extend([
        "\n# ==================================",
        "# Step 2: ãƒ‡ãƒ¼ã‚¿æ¦‚è¦ã®æŠŠæ¡",
        "# ==================================",
        "### ãƒ‡ãƒ¼ã‚¿ã®ã‚«ãƒ©ãƒ åã¨ã‚µãƒ³ãƒ—ãƒ«",
        "ä»¥ä¸‹ã«ã€åˆ†æå¯¾è±¡ã¨ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã®ã‚«ãƒ©ãƒ æ§‹æˆã¨å…ˆé ­æ•°è¡Œã®ã‚µãƒ³ãƒ—ãƒ«ã‚’ç¤ºã—ã¾ã™ã€‚ã“ã‚Œã‚’å…ƒã«åˆ†æã‚’é€²ã‚ã¦ãã ã•ã„ã€‚",
        "--- ãƒ‡ãƒ¼ã‚¿æ¦‚è¦ ---",
        data_context,
        "--- ã“ã“ã¾ã§ ---",
        f"\nä»Šå›ã®åˆ†æã®ç›®çš„å¤‰æ•°ã¯ `{target_col}` ã§ã™ã€‚"
    ])

    prompt.extend([
        "\n# ==================================",
        f"# Step 3: {analysis_goal}ã®ãŸã‚ã®ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ã¨è©•ä¾¡",
        "# ==================================",
        "### å®Ÿè¡Œã—ã¦ã»ã—ã„ã‚¿ã‚¹ã‚¯:",
    ])
    
    tasks = [f"- **ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ**: `os.makedirs(save_folder_path, exist_ok=True)` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"]
    
    # ...(ä»¥é™ã®ã‚¿ã‚¹ã‚¯ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ã¯çœç•¥)...

    prompt.append("\n".join(tasks))
    prompt.append("\n---\nä»¥ä¸Šã®å†…å®¹ã§ã€Pythonã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚")
    
    return "\n".join(prompt)


# --- Streamlit ã‚¢ãƒ—ãƒªã®UIè¨­å®š ---
st.set_page_config(page_title="ğŸ¤– AIãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ“ãƒ«ãƒ€ãƒ¼", layout="wide")
st.title("ğŸ¤– AIãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ“ãƒ«ãƒ€ãƒ¼ for Data Analysis")
st.write("ãƒ‡ãƒ¼ã‚¿åˆ†æã®ã‚¿ã‚¹ã‚¯ã‚’AIã«ä¾é ¼ã™ã‚‹ãŸã‚ã®ã€å®Œç’§ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è‡ªå‹•ç”Ÿæˆã—ã¾ã™ã€‚")

# --- UIè¦ç´ ã®åˆæœŸåŒ– (çœç•¥) ---
if 'data_context' not in st.session_state:
    st.session_state.data_context = ""


with st.sidebar:
    st.header("âš™ï¸ è¨­å®šé …ç›®")
    
    st.subheader("1. åˆ†æã®ã‚´ãƒ¼ãƒ«ã‚’é¸æŠ")
    analysis_goal = st.radio("ã“ã®åˆ†æã®ä¸»ãªç›®çš„ã¯ï¼Ÿ", ["äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰", "è¦å› åˆ†æ"], horizontal=True)

    problem_type = st.radio("2. åˆ†æã®ç›®çš„ã‚’é¸æŠ", ["åˆ†é¡", "å›å¸°", "æ™‚ç³»åˆ—äºˆæ¸¬"], horizontal=True)

    st.subheader("3. ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆç”¨ï¼‰")
    source_type = st.radio("ãƒ‡ãƒ¼ã‚¿ã®å½¢å¼", ["å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«", "Kaggleå½¢å¼"], horizontal=True)

    if source_type == "Kaggleå½¢å¼":
        st.write("Google Driveå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        train_path = st.text_input("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ (train.csv) ã®ãƒ‘ã‚¹", "/content/drive/MyDrive/kaggle/train.csv")
        test_path = st.text_input("ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ (test.csv) ã®ãƒ‘ã‚¹", "/content/drive/MyDrive/kaggle/test.csv")
        submit_path = st.text_input("æå‡ºç”¨ã‚µãƒ³ãƒ—ãƒ« (sample_submission.csv) ã®ãƒ‘ã‚¹", "/content/drive/MyDrive/kaggle/sample_submission.csv")
    else: # å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«
        st.write("Google Driveå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        single_path = st.text_input("CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹", "/content/drive/MyDrive/data/my_data.csv")

    st.subheader("4. ãƒ‡ãƒ¼ã‚¿ã®æƒ…å ±ã‚’å…¥åŠ›")
    target_col = st.text_input("ç›®çš„å¤‰æ•°ã®åˆ—å", "y" if problem_type == "æ™‚ç³»åˆ—äºˆæ¸¬" else "survived")

    # ### â–¼â–¼â–¼ ã“ã“ã‹ã‚‰ãŒå¤‰æ›´ãƒ»è¿½åŠ éƒ¨åˆ†ã§ã™ â–¼â–¼â–¼
    st.subheader("é‡è¦ï¼šãƒ‡ãƒ¼ã‚¿æ¦‚è¦ã®è‡ªå‹•å…¥åŠ›")
    uploaded_file_for_context = st.file_uploader(
        "ã“ã“ã«CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦æ¦‚è¦ã‚’è‡ªå‹•ç”Ÿæˆ",
        type=['csv'],
        help="ã“ã“ã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€ä¸‹ã®ã€Œãƒ‡ãƒ¼ã‚¿æ¦‚è¦ã€ã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã ã‘ã«ä½¿ã‚ã‚Œã¾ã™ã€‚ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸­èº«ã¯é€ä¿¡ã•ã‚Œã¾ã›ã‚“ã€‚"
    )

    # ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸã‚‰ã€infoã¨headã‚’ç”Ÿæˆã—ã¦ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
    if uploaded_file_for_context is not None:
        try:
            df_context = pd.read_csv(uploaded_file_for_context)
            
            # df.info()ã®çµæœã‚’æ–‡å­—åˆ—ã¨ã—ã¦å–å¾—
            buffer = StringIO()
            df_context.info(buf=buffer)
            info_str = buffer.getvalue()
            
            # df.head()ã®çµæœã‚’æ–‡å­—åˆ—ï¼ˆMarkdownå½¢å¼ï¼‰ã¨ã—ã¦å–å¾—
            head_str = df_context.head().to_markdown()
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
            st.session_state.data_context = f"ã€df.info()ã€‘\n{info_str}\n\nã€df.head()ã€‘\n{head_str}"
            st.success("ãƒ‡ãƒ¼ã‚¿æ¦‚è¦ã‚’ç”Ÿæˆã—ã¾ã—ãŸï¼")
        except Exception as e:
            st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

    data_context = st.text_area(
        "ãƒ‡ãƒ¼ã‚¿æ¦‚è¦ï¼ˆè‡ªå‹•å…¥åŠ›ï¼‰",
        value=st.session_state.data_context, # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‹ã‚‰å€¤ã‚’èª­ã¿è¾¼ã‚€
        height=200,
        help="ä¸Šã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’ä½¿ã†ã¨ã€ã“ã®æ¬„ã«è‡ªå‹•ã§å…¥åŠ›ã•ã‚Œã¾ã™ã€‚"
    )
    # ### â–²â–²â–² ã“ã“ã¾ã§ãŒå¤‰æ›´ãƒ»è¿½åŠ éƒ¨åˆ†ã§ã™ â–²â–²â–²

    # (ä»¥é™ã®UIè¨­å®šã¯å‰å›ã®ã‚³ãƒ¼ãƒ‰ã¨åŒæ§˜)
    # ...
    # (ä»®ã®å€¤ã‚’è¨­å®š)
    models, use_ensemble, tune_hyperparams, ts_features, include_corr, graphs, save_dir_path = ["LightGBM"], False, False, [], False, [], ""


# --- ãƒ¡ã‚¤ãƒ³ç”»é¢ã«ç”Ÿæˆã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¡¨ç¤º ---
st.header("å‡ºåŠ›ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ")
st.info("ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ã€AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã«è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„ã€‚")

if all([problem_type, target_col, models, source_type, data_context]):
    generated_prompt_text = generate_prompt(
        problem_type, source_type, analysis_goal, data_context,
        train_path, test_path, submit_path, single_path,
        target_col, id_col, time_col,
        models, use_ensemble, tune_hyperparams,
        ts_features, include_corr, graphs,
        save_dir_path
    )
    st.text_area("ç”Ÿæˆã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ", generated_prompt_text, height=600)
else:
    st.warning("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§å¿…é ˆé …ç›®ï¼ˆã‚´ãƒ¼ãƒ«ã€ç›®çš„ã€ãƒ‡ãƒ¼ã‚¿æ¦‚è¦ãªã©ï¼‰ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
